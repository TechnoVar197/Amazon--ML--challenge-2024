{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WIewVI1bzo2l",
        "outputId": "74add10f-d8a6-4de5-a133-254f02c589a2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "47072it [44:25,  6.23it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error occurred for https://m.media-amazon.com/images/I/51SpXWGC9GL.jpg: HTTPSConnectionPool(host='m.media-amazon.com', port=443): Max retries exceeded with url: /images/I/51SpXWGC9GL.jpg (Caused by SSLError(SSLError(1, '[SSL: TLSV1_ALERT_INTERNAL_ERROR] tlsv1 alert internal error (_ssl.c:1007)')))\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "50914it [48:04,  4.59it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error occurred for https://m.media-amazon.com/images/I/51X-TDHLzsL.jpg: HTTPSConnectionPool(host='m.media-amazon.com', port=443): Max retries exceeded with url: /images/I/51X-TDHLzsL.jpg (Caused by SSLError(SSLError(1, '[SSL: TLSV1_ALERT_INTERNAL_ERROR] tlsv1 alert internal error (_ssl.c:1007)')))\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "80503it [1:17:28, 15.87it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error occurred for https://m.media-amazon.com/images/I/610-TNUOrPL.jpg: [Errno 13] Permission denied: 'images\\\\970563.jpg'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "112362it [1:53:08, 15.50it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error occurred for https://m.media-amazon.com/images/I/61l9kNwjFeL.jpg: [Errno 13] Permission denied: 'images\\\\892291.jpg'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "131187it [2:21:00, 15.51it/s]\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "\n",
        "def download_images(image_links, group_ids, save_dir):\n",
        "    # Create a directory if it doesn't exist\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "    # Iterate through each URL in the list and download the image\n",
        "    for i, url in tqdm(enumerate(image_links)):\n",
        "        try:\n",
        "            # Use group_id as the image filename\n",
        "            group_id = group_ids[i]\n",
        "            image_name = f\"{group_id}.jpg\"  # Save with group_id as name, using .jpg extension\n",
        "            image_path = os.path.join(save_dir, image_name)\n",
        "\n",
        "            # Get the image from the URL\n",
        "            response = requests.get(url, stream=True)\n",
        "            if response.status_code == 200:\n",
        "                with open(image_path, 'wb') as f:\n",
        "                    for chunk in response.iter_content(1024):\n",
        "                        f.write(chunk)\n",
        "            else:\n",
        "                print(f\"Failed to download image from {url}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error occurred for {url}: {e}\")\n",
        "\n",
        "# Example usage\n",
        "train_df = pd.read_csv('dataset/test.csv')\n",
        "image_dir = 'images'\n",
        "\n",
        "# Call the function with image links and group ids\n",
        "download_images(train_df['image_link'].tolist(), train_df['group_id'].tolist(), image_dir)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BXm3Uyl2IDLG",
        "outputId": "97e094f3-8bb6-4d45-9301-b4a5b99b775f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting easyocr\n",
            "  Downloading easyocr-1.7.1-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from easyocr) (2.4.0+cu121)\n",
            "Requirement already satisfied: torchvision>=0.5 in /usr/local/lib/python3.10/dist-packages (from easyocr) (0.19.0+cu121)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (from easyocr) (4.10.0.84)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from easyocr) (1.13.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from easyocr) (1.26.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from easyocr) (9.4.0)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from easyocr) (0.23.2)\n",
            "Collecting python-bidi (from easyocr)\n",
            "  Downloading python_bidi-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from easyocr) (6.0.2)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.10/dist-packages (from easyocr) (2.0.6)\n",
            "Collecting pyclipper (from easyocr)\n",
            "  Downloading pyclipper-1.3.0.post5-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (9.0 kB)\n",
            "Collecting ninja (from easyocr)\n",
            "  Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl.metadata (5.3 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (3.16.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (2024.6.1)\n",
            "Requirement already satisfied: imageio>=2.33 in /usr/local/lib/python3.10/dist-packages (from scikit-image->easyocr) (2.34.2)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image->easyocr) (2024.8.30)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.10/dist-packages (from scikit-image->easyocr) (24.1)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.10/dist-packages (from scikit-image->easyocr) (0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->easyocr) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->easyocr) (1.3.0)\n",
            "Downloading easyocr-1.7.1-py3-none-any.whl (2.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.2/307.2 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyclipper-1.3.0.post5-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (908 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m908.3/908.3 kB\u001b[0m \u001b[31m41.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_bidi-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (281 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m281.3/281.3 kB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: python-bidi, pyclipper, ninja, easyocr\n",
            "Successfully installed easyocr-1.7.1 ninja-1.11.1.1 pyclipper-1.3.0.post5 python-bidi-0.6.0\n"
          ]
        }
      ],
      "source": [
        "!pip install easyocr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OmKV8AUsFrLB",
        "outputId": "ead9a539-0c00-4353-a33e-0dccc8f2b6be"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:easyocr.easyocr:Using CPU. Note: This module is much faster with a GPU.\n",
            "WARNING:easyocr.easyocr:Downloading detection model, please wait. This may take several minutes depending upon your network connection.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Progress: |██████████████████████████████████████████████████| 100.0% Complete"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:easyocr.easyocr:Downloading recognition model, please wait. This may take several minutes depending upon your network connection.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Progress: |██████████████████████████████████████████████████| 100.0% Complete"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/easyocr/detection.py:78: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
            "/usr/local/lib/python3.10/dist-packages/easyocr/recognition.py:169: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict = torch.load(model_path, map_location=device)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import cv2\n",
        "from PIL import Image, ImageEnhance\n",
        "import sys\n",
        "import os\n",
        "import re\n",
        "# Correct the path based on the directory structure you extracted\n",
        "sys.path.append('/content/student_resource 3/student_resource 3') # Fixed path\n",
        "import easyocr\n",
        "from tqdm import tqdm\n",
        "from src.constants import entity_unit_map, allowed_units # Now this should work\n",
        "\n",
        "# Initialize EasyOCR Reader\n",
        "reader = easyocr.Reader(['en'], gpu=False)\n",
        "\n",
        "# [Define your helper functions here as before]\n",
        "\n",
        "# Download images\n",
        "#print(\"Downloading images...\")\n",
        "#download_images(df['image_link'], save_dir=image_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1N3gBhNGJh5u"
      },
      "outputs": [],
      "source": [
        "# Load train data\n",
        "df = pd.read_csv('/content/student_resource 3/student_resource 3/dataset/train.csv', index_col=False) # Changed directory to the correct location\n",
        "\n",
        "# Create 'index' column if missing\n",
        "if 'index' not in df.columns:\n",
        "    df.reset_index(inplace=True)\n",
        "    df.rename(columns={'index': 'index'}, inplace=True)\n",
        "\n",
        "# Ensure output directory exists\n",
        "image_dir = '/content/student_resource 3/student_resource 3/images' # Changed directory to the correct location\n",
        "os.makedirs(image_dir, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8rPjkkLSIo8y"
      },
      "outputs": [],
      "source": [
        "unit_mapping = {\n",
        "    'g': 'gram',\n",
        "    'grams': 'gram',\n",
        "    'kgs': 'kilogram',\n",
        "    'kg': 'kilogram',\n",
        "    'kilograms': 'kilogram',\n",
        "    'lbs': 'pound',\n",
        "    'lb': 'pound',\n",
        "    'oz': 'ounce',\n",
        "    'ounces': 'ounce',\n",
        "    'mg': 'milligram',\n",
        "    'mcg': 'microgram',\n",
        "    'cm': 'centimetre',\n",
        "    'cms': 'centimetre',\n",
        "    'mm': 'millimetre',\n",
        "    'm': 'metre',\n",
        "    'in': 'inch',\n",
        "    'inches': 'inch',\n",
        "    'ft': 'foot',\n",
        "    'feet': 'foot',\n",
        "    'yd': 'yard',\n",
        "    'yards': 'yard',\n",
        "    'kv': 'kilovolt',\n",
        "    'mv': 'millivolt',\n",
        "    'v': 'volt',\n",
        "    'w': 'watt',\n",
        "    'kw': 'kilowatt',\n",
        "    'l': 'litre',\n",
        "    'ml': 'millilitre',\n",
        "    'liters': 'litre',\n",
        "    'litres': 'litre',\n",
        "    'cc': 'cubic centimetre',\n",
        "    'cu ft': 'cubic foot',\n",
        "    'cu in': 'cubic inch',\n",
        "    # Add more mappings as necessary\n",
        "}\n",
        "\n",
        "# Conversion factors between units (unit_from, unit_to): factor\n",
        "conversion_factors = {\n",
        "    ('kilogram', 'gram'): 1000,\n",
        "    ('pound', 'gram'): 453.592,\n",
        "    ('ounce', 'gram'): 28.3495,\n",
        "    ('milligram', 'gram'): 0.001,\n",
        "    ('microgram', 'gram'): 1e-6,\n",
        "    ('kilovolt', 'volt'): 1000,\n",
        "    ('millivolt', 'volt'): 0.001,\n",
        "    ('kilowatt', 'watt'): 1000,\n",
        "    ('millilitre', 'litre'): 0.001,\n",
        "    ('centimetre', 'metre'): 0.01,\n",
        "    ('millimetre', 'metre'): 0.001,\n",
        "    ('inch', 'metre'): 0.0254,\n",
        "    ('foot', 'metre'): 0.3048,\n",
        "    ('yard', 'metre'): 0.9144,\n",
        "    # Add more conversion factors as needed\n",
        "}\n",
        "\n",
        "def preprocess_image(image_path):\n",
        "    # Load image\n",
        "    image = Image.open(image_path)\n",
        "    # Convert to grayscale\n",
        "    image = image.convert('L')\n",
        "    # Enhance contrast\n",
        "    enhancer = ImageEnhance.Contrast(image)\n",
        "    image = enhancer.enhance(2)\n",
        "    # Convert to OpenCV format\n",
        "    image = np.array(image)\n",
        "    # Apply thresholding\n",
        "    _, image = cv2.threshold(image, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
        "    # Return PIL image\n",
        "    return Image.fromarray(image)\n",
        "\n",
        "def extract_text(image):\n",
        "    result = reader.readtext(np.array(image), detail=0)\n",
        "    return ' '.join(result)\n",
        "\n",
        "def extract_entity(text, entity_name):\n",
        "    patterns = {\n",
        "        'item_weight': r'(\\d+(\\.\\d+)?)\\s*(\\w+)',\n",
        "        'maximum_weight_recommendation': r'(\\d+(\\.\\d+)?)\\s*(\\w+)',\n",
        "        'width': r'(\\d+(\\.\\d+)?)\\s*(\\w+)',\n",
        "        'height': r'(\\d+(\\.\\d+)?)\\s*(\\w+)',\n",
        "        'depth': r'(\\d+(\\.\\d+)?)\\s*(\\w+)',\n",
        "        'voltage': r'(\\d+(\\.\\d+)?)\\s*(\\w+)',\n",
        "        'wattage': r'(\\d+(\\.\\d+)?)\\s*(\\w+)',\n",
        "        'item_volume': r'(\\d+(\\.\\d+)?)\\s*(\\w+)',\n",
        "    }\n",
        "    pattern = patterns.get(entity_name)\n",
        "    matches = re.findall(pattern, text, re.IGNORECASE)\n",
        "    if matches:\n",
        "        for match in matches:\n",
        "            value = match[0]\n",
        "            unit = match[2].lower()\n",
        "            return value, unit\n",
        "    return None, None\n",
        "\n",
        "def normalize_unit(unit):\n",
        "    unit = unit.lower()\n",
        "    unit = unit.strip('.')\n",
        "    if unit in unit_mapping:\n",
        "        return unit_mapping[unit]\n",
        "    else:\n",
        "        return unit\n",
        "\n",
        "def convert_unit(value, unit, entity_name):\n",
        "    target_units = entity_unit_map[entity_name]\n",
        "    if unit in target_units:\n",
        "        return value, unit  # No conversion needed\n",
        "    else:\n",
        "        for target_unit in target_units:\n",
        "            key = (unit, target_unit)\n",
        "            if key in conversion_factors:\n",
        "                value_in_target_unit = float(value) * conversion_factors[key]\n",
        "                return str(value_in_target_unit), target_unit\n",
        "        # If no conversion possible, return original\n",
        "        return value, unit\n",
        "\n",
        "def format_prediction(value, unit):\n",
        "    value = float(value)\n",
        "    formatted_value = f\"{value:.2f}\".rstrip('0').rstrip('.')\n",
        "    prediction = f\"{formatted_value} {unit}\"\n",
        "    return prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7c_PAq4gInfw",
        "outputId": "ad50a5dd-de3f-4dfa-c01a-eac93c29a6ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing images...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 263859/263859 [00:27<00:00, 9687.69it/s] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predictions saved to train_predictions.csv\n"
          ]
        }
      ],
      "source": [
        "predictions = []\n",
        "\n",
        "print(\"Processing images...\")\n",
        "for idx, row in tqdm(df.iterrows(), total=df.shape[0]):\n",
        "    index = row['index']\n",
        "    image_link = row['image_link']\n",
        "    entity_name = row['entity_name']\n",
        "    image_filename = os.path.basename(image_link)\n",
        "    image_path = os.path.join(image_dir, image_filename)\n",
        "\n",
        "    if not os.path.exists(image_path):\n",
        "        # Image not found, skip\n",
        "        prediction = ''\n",
        "        predictions.append({'index': index, 'prediction': prediction})\n",
        "        continue\n",
        "\n",
        "    # Preprocess image\n",
        "    preprocessed_image = preprocess_image(image_path)\n",
        "\n",
        "    # Extract text\n",
        "    text = extract_text(preprocessed_image)\n",
        "\n",
        "    # Extract entity value\n",
        "    value, unit = extract_entity(text, entity_name)\n",
        "\n",
        "    if value and unit:\n",
        "        # Normalize unit\n",
        "        unit = normalize_unit(unit)\n",
        "\n",
        "        # Convert unit if necessary\n",
        "        value, unit = convert_unit(value, unit, entity_name)\n",
        "\n",
        "        # Validate unit\n",
        "        if unit in entity_unit_map[entity_name]:\n",
        "            prediction = format_prediction(value, unit)\n",
        "        else:\n",
        "            prediction = ''\n",
        "    else:\n",
        "        prediction = ''\n",
        "\n",
        "    predictions.append({'index': index, 'prediction': prediction})\n",
        "\n",
        "# Create DataFrame and save predictions\n",
        "output_df = pd.DataFrame(predictions)\n",
        "output_df.to_csv('train_predictions.csv', index=False)\n",
        "print(\"Predictions saved to train_predictions.csv\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BDN-Qddw0XX0",
        "outputId": "d5c6bbc7-1499-4ff4-d093-69a26b4a0aaf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predictions saved to test_out.csv\n"
          ]
        }
      ],
      "source": [
        "# Create DataFrame and save predictions\n",
        "output_df = pd.DataFrame(predictions)\n",
        "output_df.to_csv('test_out.csv', index=False)\n",
        "print(\"Predictions saved to test_out.csv\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
