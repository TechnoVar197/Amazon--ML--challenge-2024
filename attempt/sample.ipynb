{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import cv2\n",
    "from PIL import Image, ImageEnhance\n",
    "import easyocr\n",
    "from tqdm import tqdm\n",
    "import pytesseract\n",
    "from src.utils import download_images\n",
    "from src.constants import entity_unit_map\n",
    "from src.constants import allowed_units\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using CPU. Note: This module is much faster with a GPU.\n",
      "c:\\Users\\Aniruddha\\anaconda3\\Lib\\site-packages\\easyocr\\detection.py:78: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  net.load_state_dict(copyStateDict(torch.load(trained_model, map_location=device)))\n",
      "c:\\Users\\Aniruddha\\anaconda3\\Lib\\site-packages\\easyocr\\recognition.py:169: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(model_path, map_location=device)\n"
     ]
    }
   ],
   "source": [
    "# Initialize EasyOCR Reader\n",
    "reader = easyocr.Reader(['en'], gpu=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytesseract.pytesseract.tesseract_cmd = r'C:/Tools/AddLib/Tesseract/tesseract.exe'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unit mappings for normalization\n",
    "unit_mapping = {\n",
    "    'g': 'gram',\n",
    "    'grams': 'gram',\n",
    "    'kgs': 'kilogram',\n",
    "    'kg': 'kilogram',\n",
    "    'kilograms': 'kilogram',\n",
    "    'lbs': 'pound',\n",
    "    'lb': 'pound',\n",
    "    'pounds': 'pound',\n",
    "    'oz': 'ounce',\n",
    "    'ounces': 'ounce',\n",
    "    'mg': 'milligram',\n",
    "    'mcg': 'microgram',\n",
    "    'cm': 'centimetre',\n",
    "    'cms': 'centimetre',\n",
    "    'mm': 'millimetre',\n",
    "    'm': 'metre',\n",
    "    'meters': 'metre',\n",
    "    'metres': 'metre',\n",
    "    'in': 'inch',\n",
    "    'inches': 'inch',\n",
    "    'ft': 'foot',\n",
    "    'feet': 'foot',\n",
    "    'yd': 'yard',\n",
    "    'yards': 'yard',\n",
    "    'kv': 'kilovolt',\n",
    "    'kv': 'kilovolt',\n",
    "    'mv': 'millivolt',\n",
    "    'v': 'volt',\n",
    "    'w': 'watt',\n",
    "    'kw': 'kilowatt',\n",
    "    'l': 'litre',\n",
    "    'liters': 'litre',\n",
    "    'litres': 'litre',\n",
    "    'ml': 'millilitre',\n",
    "    'cc': 'cubic centimetre',\n",
    "    'cu ft': 'cubic foot',\n",
    "    'cu in': 'cubic inch',\n",
    "    # Add more mappings as necessary\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_contrast_brightness(image, contrast=1.5, brightness=0):\n",
    "    return cv2.convertScaleAbs(image, alpha=contrast, beta=brightness)\n",
    "\n",
    "def denoise_image(image):\n",
    "    return cv2.fastNlMeansDenoising(image, None, h=30)\n",
    "\n",
    "def deskew(image):\n",
    "    coords = np.column_stack(np.where(image > 0))\n",
    "    angle = cv2.minAreaRect(coords)[-1]\n",
    "    if angle < -45:\n",
    "        angle = -(90 + angle)\n",
    "    else:\n",
    "        angle = -angle\n",
    "    (h, w) = image.shape[:2]\n",
    "    center = (w // 2, h // 2)\n",
    "    M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "    rotated = cv2.warpAffine(image, M, (w, h),\n",
    "                            flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_REPLICATE)\n",
    "    return rotated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image_path):\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "    preprocessings = []\n",
    "\n",
    "    # Original grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    preprocessings.append(gray)\n",
    "\n",
    "    # Denoised image\n",
    "    denoised = denoise_image(gray)\n",
    "    preprocessings.append(denoised)\n",
    "\n",
    "    # Adjusted contrast and brightness\n",
    "    adjusted = adjust_contrast_brightness(gray)\n",
    "    preprocessings.append(adjusted)\n",
    "\n",
    "    # Adaptive thresholding\n",
    "    thresh = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
    "                                cv2.THRESH_BINARY, 31, 2)\n",
    "    preprocessings.append(thresh)\n",
    "\n",
    "    # Deskewed image\n",
    "    try:\n",
    "        deskewed = deskew(gray)\n",
    "        preprocessings.append(deskewed)\n",
    "    except Exception as e:\n",
    "        pass  # If deskewing fails, skip it\n",
    "\n",
    "    return preprocessings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text(image):\n",
    "    # Use Tesseract OCR with LSTM model\n",
    "    custom_config = r'--oem 3 --psm 6 -l eng'\n",
    "    text = pytesseract.image_to_string(image)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_entity(text, entity_name):\n",
    "    # Define keywords for context\n",
    "    keywords = {\n",
    "        'item_weight': ['weight', 'wt', 'net weight', 'nw'],\n",
    "        'maximum_weight_recommendation': ['maximum weight', 'max weight', 'max wt'],\n",
    "        'width': ['width', 'w'],\n",
    "        'height': ['height', 'h'],\n",
    "        'depth': ['depth', 'd'],\n",
    "        'voltage': ['voltage', 'volt', 'v'],\n",
    "        'wattage': ['wattage', 'watt', 'w'],\n",
    "        'item_volume': ['volume', 'vol', 'capacity'],\n",
    "    }\n",
    "    # Regex pattern to match numbers and units\n",
    "    unit_list = '|'.join(unit_mapping.keys())\n",
    "    pattern = r'(\\d+(?:[\\.,]\\d+)?)\\s*(%s)' % unit_list\n",
    "    matches = re.finditer(pattern, text, re.IGNORECASE)\n",
    "    for match in matches:\n",
    "        value = match.group(1).replace(',', '.')\n",
    "        unit = match.group(2).lower()\n",
    "        # Check for keywords near the match\n",
    "        start_idx = max(0, match.start() - 50)\n",
    "        end_idx = match.end() + 50\n",
    "        surrounding_text = text[start_idx:end_idx].lower()\n",
    "        if any(keyword in surrounding_text for keyword in keywords.get(entity_name, [])):\n",
    "            return value, unit\n",
    "    return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_unit(unit):\n",
    "    unit = unit.lower()\n",
    "    unit = unit.strip('.')\n",
    "    if unit in unit_mapping:\n",
    "        return unit_mapping[unit]\n",
    "    else:\n",
    "        return unit\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_prediction(value, unit):\n",
    "    value = float(value)\n",
    "    formatted_value = f\"{value:.2f}\".rstrip('0').rstrip('.')\n",
    "    prediction = f\"{formatted_value} {unit}\"\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test data\n",
    "test_df = pd.read_csv('dataset/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure 'index' is in columns\n",
    "if 'index' not in test_df.columns:\n",
    "    test_df.reset_index(inplace=True)\n",
    "    test_df.rename(columns={'index': 'index'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['index', 'image_link', 'group_id', 'entity_name'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(test_df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure output directory exists\n",
    "image_dir = 'test_images'\n",
    "os.makedirs(image_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▊  | 103005/131187 [00:40<00:02, 11059.44it/s]"
     ]
    }
   ],
   "source": [
    "# Download images\n",
    "print(\"Downloading images...\")\n",
    "download_images(test_df['image_link'],image_dir)\n",
    "\n",
    "predictions = []\n",
    "\n",
    "print(\"Processing images...\")\n",
    "for idx, row in tqdm(test_df.iterrows(), total=test_df.shape[0]):\n",
    "    index = row['index']\n",
    "    image_link = row['image_link']\n",
    "    entity_name = row['entity_name']\n",
    "    image_filename = os.path.basename(image_link)\n",
    "    image_path = os.path.join(image_dir, image_filename)\n",
    "\n",
    "    if not os.path.exists(image_path):\n",
    "        # Image not found, skip\n",
    "        prediction = ''\n",
    "        predictions.append({'index': index, 'prediction': prediction})\n",
    "        continue\n",
    "\n",
    "    # Preprocess image with multiple methods\n",
    "    preprocessed_images = preprocess_image(image_path)\n",
    "\n",
    "    # Try extracting text from each preprocessed image\n",
    "    extracted_value = None\n",
    "    extracted_unit = None\n",
    "    for preprocessed_image in preprocessed_images:\n",
    "        # Convert to PIL Image for Tesseract\n",
    "        pil_image = Image.fromarray(preprocessed_image)\n",
    "        text = extract_text(pil_image)\n",
    "        value, unit = extract_entity(text, entity_name)\n",
    "        if value and unit:\n",
    "            extracted_value = value\n",
    "            extracted_unit = unit\n",
    "            break  # Stop if extraction is successful\n",
    "\n",
    "    if extracted_value and extracted_unit:\n",
    "        # Normalize unit\n",
    "        unit = normalize_unit(extracted_unit)\n",
    "\n",
    "        # Validate unit\n",
    "        if unit in entity_unit_map[entity_name]:\n",
    "            prediction = format_prediction(extracted_value, unit)\n",
    "        else:\n",
    "            prediction = ''\n",
    "    else:\n",
    "        prediction = ''\n",
    "\n",
    "    predictions.append({'index': index, 'prediction': prediction})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "parent = \"D:/Pfiles/Amazon HAckthon\"\n",
    "dir = \"test_images\"\n",
    "path = os.path.join(parent, dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory 'test_images' has been removed successfully\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    shutil.rmtree(path)\n",
    "    print(\"Directory '% s' has been removed successfully\" % dir)\n",
    "except OSError as error:\n",
    "    print(error)\n",
    "    print(\"Directory '% s' can not be removed\" % dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame and save predictions\n",
    "output_df = pd.DataFrame(predictions)\n",
    "output_df.to_csv('test_out.csv', index=False)\n",
    "print(\"Predictions saved to test_out.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_df.tail(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
